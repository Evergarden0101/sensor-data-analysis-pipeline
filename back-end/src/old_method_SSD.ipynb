{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, math, datetime\n",
    "import neurokit2 as nk\n",
    "import hrvanalysis as hrvana\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FUNCTIONS\n",
    "\n",
    "\"\"\"Take cleaned ecg as input and return RR intervals\"\"\"\n",
    "def find_rr_intervals(cleaned_ecg):\n",
    "    pantompkins1985 = nk.ecg_findpeaks(cleaned_ecg, method=\"pantompkins1985\") # find the R peaks\n",
    "    hrv_df = pd.DataFrame(pantompkins1985)\n",
    "    hrv_df[\"RR Intervals\"] = hrv_df[\"ECG_R_Peaks\"].diff() # calculate the value difference between two adjacent points\n",
    "    hrv_df.loc[0, \"RR Intervals\"]=hrv_df.loc[0]['ECG_R_Peaks'] # the first datapoint contain Nan \n",
    "\n",
    "    return hrv_df\n",
    "\n",
    "\n",
    "\"\"\"Take the RR intervals and returns a cleaned version of them\"\"\"\n",
    "def clean_rr_intervals(hrv_df):\n",
    "    clean_rri = hrv_df['RR Intervals'].values\n",
    "    clean_rri = hrvana.remove_outliers(rr_intervals=clean_rri, low_rri=300, high_rri=2000)\n",
    "    #clean_rri = np.array(clean_rri)\n",
    "    print(type(clean_rri))\n",
    "    print(f\"Indices of nan values 1: {np.argwhere(np.isnan(clean_rri))}\")\n",
    "    #nans, x= nan_helper(clean_rri)\n",
    "    #clean_rri[nans]= np.interp(x(nans), x(~nans), clean_rri[~nans])\n",
    "    clean_rri = hrvana.interpolate_nan_values(rr_intervals=clean_rri, interpolation_method=\"linear\")\n",
    "    clean_rri = hrvana.remove_ectopic_beats(rr_intervals=clean_rri, method=\"malik\")\n",
    "    clean_rri = hrvana.interpolate_nan_values(rr_intervals=clean_rri, interpolation_method=\"linear\")\n",
    "    #clean_rri = np.array(clean_rri)\n",
    "    print(f\"Indices of nan values 2: {np.argwhere(np.isnan(clean_rri))}\")\n",
    "    #nans, x= nan_helper(clean_rri)\n",
    "    #clean_rri[nans]= np.interp(x(nans), x(~nans), clean_rri[~nans])\n",
    "    clean_rri = hrvana.interpolate_nan_values(rr_intervals=clean_rri, interpolation_method=\"linear\")\n",
    "    #clean_rri = np.array(clean_rri)\n",
    "    #nans, x= nan_helper(clean_rri)\n",
    "    #clean_rri[nans]= np.interp(x(nans), x(~nans), clean_rri[~nans])\n",
    "    print(\"check for null values in cleaned rri intervals\")\n",
    "    print(np.isnan(clean_rri).any())\n",
    "\n",
    "    #return clean_rri.tolist()\n",
    "    return clean_rri\n",
    "\n",
    "\n",
    "\"\"\"Return the REM and NREM LF/HF ranges from: Herzig et al., Reproducibility of Heart Rate Variability Is Parameter and Sleep Stage Dependent (2017).\n",
    "    All the values as a reference:\n",
    "    stage_2 = {'min': 0.68, 'median': 1.11, 'max': 2.02}\n",
    "    sws = {'min': 0.31 , 'median': 0.51, 'max': 0.90}\n",
    "    nrem = {'min': 0.31, 'median': (2.02-0.31)/2 , 'max': 2.02}\n",
    "    rem = {'min': 1.30, 'median': 2.02 , 'max': 3.22}\n",
    "\"\"\"\n",
    "def get_herzig_ranges():\n",
    "    return {\n",
    "        'nrem': {'min': 0.31, 'median': (2.02-0.31)/2 , 'max': 2.02},\n",
    "        'rem' : {'min': 1.30, 'median': 2.02 , 'max': 3.22}\n",
    "    }\n",
    "\n",
    "\n",
    "\"\"\"Return REM and NREM LF/HF ranges from: Ako et al., Correlation between electroencephalography and heart rate variability during sleep (2003)\n",
    "    All the values as a reference:\n",
    "    stage_1 = {'min': 2.30-0.29, 'median': 2.30, 'max': 2.30+0.29}\n",
    "    stage_2 = {'min': 1.85-0.09 , 'median': 1.85 , 'max': 1.85+0.09}\n",
    "    stage_3 = {'min': 0.78-0.06 , 'median': 0.78, 'max': 0.78+0.06}\n",
    "    stage_4 = {'min': 0.86-0.14, 'median': 0.86, 'max': 0.86+0.14}\n",
    "    rem = {'min': 2.51-0.17, 'median': 2.51, 'max': 2.51+0.17}\n",
    "\"\"\"\n",
    "def get_ako_ranges():\n",
    "    return {\n",
    "        'nrem': {'min':0.72, 'median': (2.59-0.72)/2, 'max': 2.59},\n",
    "        'rem': {'min': 2.51-0.17, 'median': 2.51 , 'max': 2.51+0.17}\n",
    "    }\n",
    "\n",
    "\n",
    "# COMPLETE PIPELINE FUNCTION\n",
    "\"\"\"\n",
    "- patient_id: id of the patient\n",
    "- week: week number\n",
    "- night_id: id of the night that specifies which file to open \n",
    "- n: first n minutes of data are selected\n",
    "- SAMPLING_RATE: desired sampling rate (default: 1000)\n",
    "\"\"\"\n",
    "\n",
    "def get_HRV_features(patient_id, week, night_id,  SAMPLING_RATE):\n",
    "    start = 0\n",
    "    print(f\"start: {start}\")\n",
    "    # Number of data points in 5 minutes\n",
    "    window_size = 5*60*SAMPLING_RATE\n",
    "    print(f\"window size: {window_size}\")\n",
    "    end = window_size\n",
    "    print(f\"end: {end}\")\n",
    "    values = []\n",
    "    y=0\n",
    "    x=0\n",
    "\n",
    "    # Open right CSV file and get ECG data\n",
    "    df = open_brux_csv(patient_id, week, night_id)\n",
    "    print(f\"dfshape: {df.shape}\")\n",
    "    ecg = df[\"ECG\"]\n",
    "    ecg_array = ecg.values.tolist()\n",
    "    print(f\"last element: {ecg_array[-1]}\")\n",
    "    print(f\" ECG Array length: {len(ecg)}\")\n",
    "\n",
    "\n",
    "    print(f\"ECG Array duration: {datetime.timedelta(seconds=(len(ecg_array)/SAMPLING_RATE))}\")\n",
    "\n",
    "\n",
    "    print(f\"ECG Array duration in minutes: {(datetime.timedelta(seconds=(len(ecg_array)/SAMPLING_RATE))).total_seconds()/60}\")\n",
    "\n",
    "    signal_duration_minutes = (datetime.timedelta(seconds=(len(ecg_array)/SAMPLING_RATE))).total_seconds() / 60\n",
    "        \n",
    "    n = math.floor(signal_duration_minutes)\n",
    "\n",
    "    while n%5!=0:\n",
    "        n = n-1\n",
    "\n",
    "    print(f\"Adapted minutes duration: {n}\")\n",
    "\n",
    "    data_points = n*60*SAMPLING_RATE\n",
    "    print(f\"New number of data points: {data_points}\")\n",
    "    ecg_nmin = ecg_array[:data_points]\n",
    "    print(f\"rounded down array length: {len(ecg_nmin)}\")\n",
    "    print(f\"last element: {ecg_nmin[-1]}\")\n",
    "\n",
    "    print(f\"Adapted Signal duration: {datetime.timedelta(seconds=(len(ecg_nmin)/SAMPLING_RATE))}\")\n",
    "\n",
    "    while end <= len(ecg_nmin):\n",
    "        print(\"Beginning of while loop\")\n",
    "        print(f\"end:{end}\")\n",
    "        print(f\"length of data: {len(ecg_nmin)}\")\n",
    "        stage = ''\n",
    "\n",
    "        # 5 minutes of ecg data\n",
    "        ecg = ecg_nmin[start:end]\n",
    "\n",
    "        print(f\"5 minutes of data: {len(ecg)}\")\n",
    "        print(f\"last element of the 5 minutes: {ecg[-1]}\")\n",
    "\n",
    "        # Filter the data with ranges specified from Barbara\n",
    "        filter_ecg = nk.signal_filter(ecg, sampling_rate=SAMPLING_RATE, lowcut=0.5, highcut=150)\n",
    "\n",
    "\n",
    "        # Clean ECG data\n",
    "        cleaned = nk.ecg_clean(filter_ecg, sampling_rate=SAMPLING_RATE, method=\"pantompkins1985\")\n",
    "\n",
    "        print(f\"cleaned isna(): {np.isnan(cleaned).any()}\")\n",
    "\n",
    "        #Find RR intervals    \n",
    "        hrv_df = find_rr_intervals(cleaned)\n",
    "\n",
    "        # Clean RR intervals\n",
    "\n",
    "        clean_rri = clean_rr_intervals(hrv_df)\n",
    "        hrv_df[\"RR Intervals\"] = clean_rri \n",
    "\n",
    "        # HRV feature extraction\n",
    "        nn_epoch = hrv_df['RR Intervals'].values\n",
    "\n",
    "        print(type(nn_epoch))\n",
    "\n",
    "        print(f\"are there nullvalues: {hrv_df['RR Intervals'].isna().any()}\")\n",
    "        print(f\"where? \")\n",
    "\n",
    "        time_features = hrvana.get_time_domain_features(nn_epoch)\n",
    "        print(f\"time_features: {time_features}\")\n",
    "        frequency_features = hrvana.get_frequency_domain_features(nn_epoch)\n",
    "        print(f\"frequency features: {frequency_features}\")\n",
    "\n",
    "        print(f\"LF/HF ratio: {frequency_features['lf_hf_ratio']}\")\n",
    "        nrem = get_herzig_ranges()['nrem']\n",
    "        rem = get_herzig_ranges()['rem']\n",
    "\n",
    "\n",
    "        if  nrem['min'] <= frequency_features['lf_hf_ratio'] <= nrem['max']:\n",
    "            stage = 'nrem'\n",
    "\n",
    "        if frequency_features['lf_hf_ratio'] < nrem['min']:\n",
    "            stage = 'nrem'\n",
    "\n",
    "        if rem['min'] <= frequency_features['lf_hf_ratio'] <= rem['max']:\n",
    "            stage = 'rem'\n",
    "\n",
    "        if frequency_features['lf_hf_ratio'] > rem['max']:\n",
    "            stage = 'rem'\n",
    "\n",
    "        values.append({\n",
    "            'start_id': start,\n",
    "            'end_id': end,\n",
    "            'LF_HF': frequency_features['lf_hf_ratio'],\n",
    "            'SD': time_features['sdnn'],\n",
    "            'stage': stage,\n",
    "            'y': y,\n",
    "            'x': x\n",
    "        })\n",
    "\n",
    "        print(f\"values appended: {values[-1]}\")\n",
    "        # Calculate the coordinates for the SleepHeatMap.vue\n",
    "        if x==((SLEEP_CYCLE/INTERVAL)-1):\n",
    "            x=0\n",
    "            y+=1\n",
    "\n",
    "        else:\n",
    "            x+=1\n",
    "\n",
    "        start = end\n",
    "        end += window_size\n",
    "\n",
    "        print(f\"start after increase: {start}\")\n",
    "        print(f\"end after increase: {end}\")\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 0\n",
      "window size: 600000\n",
      "end: 600000\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 512. KiB for an array with shape (65536,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m values \u001b[39m=\u001b[39m get_HRV_features(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m1022102\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m2000\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[20], line 91\u001b[0m, in \u001b[0;36mget_HRV_features\u001b[1;34m(patient_id, week, night_id, SAMPLING_RATE)\u001b[0m\n\u001b[0;32m     88\u001b[0m x\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     90\u001b[0m \u001b[39m# Open right CSV file and get ECG data\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m df \u001b[39m=\u001b[39m open_brux_csv(patient_id, week, night_id)\n\u001b[0;32m     92\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdfshape: \u001b[39m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m ecg \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mECG\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\back-end\\src\\preprocessing.py:11\u001b[0m, in \u001b[0;36mopen_brux_csv\u001b[1;34m(patient_id, week, night_id)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_brux_csv\u001b[39m(patient_id, week, night_id):\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_csv(DATA_PATH \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mp\u001b[39;49m\u001b[39m{\u001b[39;49;00mpatient_id\u001b[39m}\u001b[39;49;00m\u001b[39m_w\u001b[39;49m\u001b[39m{\u001b[39;49;00mweek\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mnight_id\u001b[39m}\u001b[39;49;00m\u001b[39mcFnorm.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1192\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eleon\\Desktop\\Master\\FJS 23\\Master Project\\sensor-data-analysis-pipeline\\.venv\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1801\u001b[0m, in \u001b[0;36mpandas._libs.parsers._try_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 512. KiB for an array with shape (65536,) and data type int64"
     ]
    }
   ],
   "source": [
    "values = get_HRV_features(1, 1, '1022102', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_id': 0,\n",
       "  'end_id': 600000,\n",
       "  'LF_HF': 2.0040890847972954,\n",
       "  'SD': 170.6968057441307,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 0},\n",
       " {'start_id': 600000,\n",
       "  'end_id': 1200000,\n",
       "  'LF_HF': 2.5218043895215705,\n",
       "  'SD': 176.57070906051337,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 1},\n",
       " {'start_id': 1200000,\n",
       "  'end_id': 1800000,\n",
       "  'LF_HF': 2.3772641904301004,\n",
       "  'SD': 72.93757727037564,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 2},\n",
       " {'start_id': 1800000,\n",
       "  'end_id': 2400000,\n",
       "  'LF_HF': 2.2606303346440226,\n",
       "  'SD': 126.68550206186912,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 3},\n",
       " {'start_id': 2400000,\n",
       "  'end_id': 3000000,\n",
       "  'LF_HF': 3.024098478820472,\n",
       "  'SD': 197.73358507126633,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 4},\n",
       " {'start_id': 3000000,\n",
       "  'end_id': 3600000,\n",
       "  'LF_HF': 2.4482194684560223,\n",
       "  'SD': 235.2433630897039,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 5},\n",
       " {'start_id': 3600000,\n",
       "  'end_id': 4200000,\n",
       "  'LF_HF': 3.9469487985953484,\n",
       "  'SD': 196.82730350778306,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 6},\n",
       " {'start_id': 4200000,\n",
       "  'end_id': 4800000,\n",
       "  'LF_HF': 3.9352415377434893,\n",
       "  'SD': 132.40516529682424,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 7},\n",
       " {'start_id': 4800000,\n",
       "  'end_id': 5400000,\n",
       "  'LF_HF': 5.826866229693072,\n",
       "  'SD': 127.17480359031917,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 8},\n",
       " {'start_id': 5400000,\n",
       "  'end_id': 6000000,\n",
       "  'LF_HF': 2.2730094308645064,\n",
       "  'SD': 130.0765923063291,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 9},\n",
       " {'start_id': 6000000,\n",
       "  'end_id': 6600000,\n",
       "  'LF_HF': 2.5863826373503644,\n",
       "  'SD': 192.8441207075244,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 10},\n",
       " {'start_id': 6600000,\n",
       "  'end_id': 7200000,\n",
       "  'LF_HF': 1.6189447221591373,\n",
       "  'SD': 97.73725435506444,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 11},\n",
       " {'start_id': 7200000,\n",
       "  'end_id': 7800000,\n",
       "  'LF_HF': 1.819525650155099,\n",
       "  'SD': 160.7842368969988,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 12},\n",
       " {'start_id': 7800000,\n",
       "  'end_id': 8400000,\n",
       "  'LF_HF': 2.206118243040016,\n",
       "  'SD': 211.29399288595366,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 13},\n",
       " {'start_id': 8400000,\n",
       "  'end_id': 9000000,\n",
       "  'LF_HF': 3.555122708974666,\n",
       "  'SD': 180.8670852674829,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 14},\n",
       " {'start_id': 9000000,\n",
       "  'end_id': 9600000,\n",
       "  'LF_HF': 2.7927989167693714,\n",
       "  'SD': 153.32844318973184,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 15},\n",
       " {'start_id': 9600000,\n",
       "  'end_id': 10200000,\n",
       "  'LF_HF': 2.9841653036717153,\n",
       "  'SD': 188.01890323817787,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 16},\n",
       " {'start_id': 10200000,\n",
       "  'end_id': 10800000,\n",
       "  'LF_HF': 1.7156204067152492,\n",
       "  'SD': 195.82823668217839,\n",
       "  'stage': 'rem',\n",
       "  'y': 0,\n",
       "  'x': 17},\n",
       " {'start_id': 10800000,\n",
       "  'end_id': 11400000,\n",
       "  'LF_HF': 1.9337462080233252,\n",
       "  'SD': 156.08906462306797,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 0},\n",
       " {'start_id': 11400000,\n",
       "  'end_id': 12000000,\n",
       "  'LF_HF': 2.8445476560791176,\n",
       "  'SD': 152.9614249129654,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 1},\n",
       " {'start_id': 12000000,\n",
       "  'end_id': 12600000,\n",
       "  'LF_HF': 2.1876565239271817,\n",
       "  'SD': 179.5494513055498,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 2},\n",
       " {'start_id': 12600000,\n",
       "  'end_id': 13200000,\n",
       "  'LF_HF': 2.929623302596248,\n",
       "  'SD': 210.74301246962142,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 3},\n",
       " {'start_id': 13200000,\n",
       "  'end_id': 13800000,\n",
       "  'LF_HF': 2.693784622207734,\n",
       "  'SD': 223.40274252542642,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 4},\n",
       " {'start_id': 13800000,\n",
       "  'end_id': 14400000,\n",
       "  'LF_HF': 2.335402503789671,\n",
       "  'SD': 125.04030648320601,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 5},\n",
       " {'start_id': 14400000,\n",
       "  'end_id': 15000000,\n",
       "  'LF_HF': 2.384068694944904,\n",
       "  'SD': 190.38471568228184,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 6},\n",
       " {'start_id': 15000000,\n",
       "  'end_id': 15600000,\n",
       "  'LF_HF': 3.205154727492761,\n",
       "  'SD': 182.83881116970562,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 7},\n",
       " {'start_id': 15600000,\n",
       "  'end_id': 16200000,\n",
       "  'LF_HF': 4.217298405245741,\n",
       "  'SD': 189.6345321767063,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 8},\n",
       " {'start_id': 16200000,\n",
       "  'end_id': 16800000,\n",
       "  'LF_HF': 3.9757825446481734,\n",
       "  'SD': 282.20718676928595,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 9},\n",
       " {'start_id': 16800000,\n",
       "  'end_id': 17400000,\n",
       "  'LF_HF': 7.7601087055497695,\n",
       "  'SD': 223.02002655611793,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 10},\n",
       " {'start_id': 17400000,\n",
       "  'end_id': 18000000,\n",
       "  'LF_HF': 4.105657610625793,\n",
       "  'SD': 183.72128246848558,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 11},\n",
       " {'start_id': 18000000,\n",
       "  'end_id': 18600000,\n",
       "  'LF_HF': 23.633308098111982,\n",
       "  'SD': 177.6158696563407,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 12},\n",
       " {'start_id': 18600000,\n",
       "  'end_id': 19200000,\n",
       "  'LF_HF': 2.9522606720154805,\n",
       "  'SD': 164.4147275313981,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 13},\n",
       " {'start_id': 19200000,\n",
       "  'end_id': 19800000,\n",
       "  'LF_HF': 42.115735671356724,\n",
       "  'SD': 248.599344836871,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 14},\n",
       " {'start_id': 19800000,\n",
       "  'end_id': 20400000,\n",
       "  'LF_HF': 22.468114259430045,\n",
       "  'SD': 209.8535187371678,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 15},\n",
       " {'start_id': 20400000,\n",
       "  'end_id': 21000000,\n",
       "  'LF_HF': 1.59718374306918,\n",
       "  'SD': 205.61153398725716,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 16},\n",
       " {'start_id': 21000000,\n",
       "  'end_id': 21600000,\n",
       "  'LF_HF': 11.788486536552895,\n",
       "  'SD': 182.4190091417177,\n",
       "  'stage': 'rem',\n",
       "  'y': 1,\n",
       "  'x': 17},\n",
       " {'start_id': 21600000,\n",
       "  'end_id': 22200000,\n",
       "  'LF_HF': 8.300892557825541,\n",
       "  'SD': 181.04122219667872,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 0},\n",
       " {'start_id': 22200000,\n",
       "  'end_id': 22800000,\n",
       "  'LF_HF': 9.611717074650025,\n",
       "  'SD': 229.03396124164652,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 1},\n",
       " {'start_id': 22800000,\n",
       "  'end_id': 23400000,\n",
       "  'LF_HF': 18.75260613690689,\n",
       "  'SD': 226.9911466271806,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 2},\n",
       " {'start_id': 23400000,\n",
       "  'end_id': 24000000,\n",
       "  'LF_HF': 7.449386716391616,\n",
       "  'SD': 236.6631945962752,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 3},\n",
       " {'start_id': 24000000,\n",
       "  'end_id': 24600000,\n",
       "  'LF_HF': 3.1946110648949566,\n",
       "  'SD': 209.79203372940876,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 4},\n",
       " {'start_id': 24600000,\n",
       "  'end_id': 25200000,\n",
       "  'LF_HF': 4.7739631240165785,\n",
       "  'SD': 208.78422651748056,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 5},\n",
       " {'start_id': 25200000,\n",
       "  'end_id': 25800000,\n",
       "  'LF_HF': 8.400733479375923,\n",
       "  'SD': 218.84947984278665,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 6},\n",
       " {'start_id': 25800000,\n",
       "  'end_id': 26400000,\n",
       "  'LF_HF': 3.7090889069591966,\n",
       "  'SD': 195.4960689724523,\n",
       "  'stage': 'rem',\n",
       "  'y': 2,\n",
       "  'x': 7}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_id': 33600000,\n",
       " 'end_id': 34200000,\n",
       " 'LF_HF': 4.239924835758465,\n",
       " 'SD': 190.55276866655515,\n",
       " 'stage': 'rem',\n",
       " 'y': 3,\n",
       " 'x': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
